import json, re, os
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_core.messages import HumanMessage
from ..state import BlogState
from ..config import settings
from ..services.velog import publish_to_velog, save_draft_to_file

if settings.google_api_key:
    os.environ["GOOGLE_API_KEY"] = settings.google_api_key

llm = ChatGoogleGenerativeAI(
    model=settings.gemini_model,
    temperature=0.2,
)
llm_writer = ChatGoogleGenerativeAI(
    model=settings.gemini_model,
    temperature=0.7,
)


# â”€â”€ Node 6: Critique â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def critique(state: BlogState) -> dict:
    """
    [Node 6] ì´ˆì•ˆ í’ˆì§ˆ + SEO ê²€í† 
    
    í‰ê°€ í•­ëª©:
    - ë‚´ìš©ì˜ ê¹Šì´ì™€ ì •í™•ì„±
    - SEO í‚¤ì›Œë“œ ìì—°ìŠ¤ëŸ¬ìš´ í¬í•¨ ì—¬ë¶€
    - ë…ì ì¹œí™”ì„± ë° ê°€ë…ì„±
    - ì‹¤ìš©ì  ê°€ì¹˜
    """
    draft = state.get("draft") or ""
    keywords = ", ".join(state.get("seo_keywords") or [])

    prompt = f"""ë‹¹ì‹ ì€ ê¸°ìˆ  ë¸”ë¡œê·¸ ì—ë””í„°ì…ë‹ˆë‹¤. ì•„ë˜ ì´ˆì•ˆì„ ê²€í† í•´ì£¼ì„¸ìš”.

SEO í‚¤ì›Œë“œ: {keywords}

--- ì´ˆì•ˆ ---
{draft[:3000]}
--- ë ---

í‰ê°€ ê¸°ì¤€:
1. ë‚´ìš©ì˜ ê¹Šì´ì™€ ì •í™•ì„± (ìµœì‹  ì •ë³´ ë°˜ì˜ ì—¬ë¶€)
2. SEO í‚¤ì›Œë“œ ìì—°ìŠ¤ëŸ¬ìš´ í¬í•¨ (ì–µì§€ìŠ¤ëŸ½ì§€ ì•Šì€ì§€)
3. ê°€ë…ì„± (ë§ˆí¬ë‹¤ìš´ êµ¬ì¡°, ë‹¨ë½ ê¸¸ì´)
4. ì‹¤ìš©ì  ê°€ì¹˜ (ë…ìê°€ ì‹¤ì œë¡œ ë„ì›€ë°›ì„ ìˆ˜ ìˆëŠ”ê°€)
5. ë„ì…ë¶€ í›… (ì²« ë¬¸ì¥ì´ ë…ìë¥¼ ì¡ì•„ë‹¹ê¸°ëŠ”ê°€)

JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µ:
{{
  "score": 7,
  "strengths": ["ê°•ì 1", "ê°•ì 2"],
  "improvements": ["ê°œì„ ì 1", "ê°œì„ ì 2"],
  "summary": "í•œ ì¤„ ì´í‰"
}}"""

    response = llm.invoke([HumanMessage(content=prompt)])

    try:
        content = re.sub(r"```(?:json)?|```", "", response.content).strip()
        data = json.loads(content)
        score = int(data.get("score", 5))
        improvements = data.get("improvements", [])
        summary = data.get("summary", "")
        critique_text = f"ì´í‰: {summary}\nê°œì„ ì :\n" + "\n".join(f"- {i}" for i in improvements)
    except Exception:
        score = 5
        critique_text = response.content.strip()

    return {
        "critique":      critique_text,
        "quality_score": score,
        "logs":          [f"ğŸ” [Critique] ì ìˆ˜: {score}/10 | {summary if 'summary' in dir() else ''}"],
    }


# â”€â”€ Node 7: Revise â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def revise(state: BlogState) -> dict:
    """
    [Node 7] í”¼ë“œë°± ë°˜ì˜ ì¬ì‘ì„±
    
    critique ë…¸ë“œì˜ ê°œì„ ì ì„ ë°˜ì˜í•´ ì´ˆì•ˆì„ ê°œì„ í•©ë‹ˆë‹¤.
    ìµœëŒ€ 2íšŒ ë°˜ë³µ (ë¬´í•œ ë£¨í”„ ë°©ì§€)
    """
    draft = state.get("draft") or ""
    critique_text = state.get("critique") or ""
    keywords = ", ".join(state.get("seo_keywords") or [])
    revision_count = state.get("revision_count") or 0

    prompt = f"""ë‹¹ì‹ ì€ ì „ë¬¸ ê¸°ìˆ  ë¸”ë¡œê·¸ ì‘ê°€ì…ë‹ˆë‹¤. í•œêµ­ì–´ë¡œ ì‘ì„±í•˜ì„¸ìš”.

í”¼ë“œë°±ì„ ë°˜ì˜í•´ ì•„ë˜ ì´ˆì•ˆì„ ê°œì„ í•´ì£¼ì„¸ìš”.

SEO í‚¤ì›Œë“œ (ìì—°ìŠ¤ëŸ½ê²Œ í¬í•¨): {keywords}

í”¼ë“œë°±:
{critique_text}

í˜„ì¬ ì´ˆì•ˆ:
{draft[:3000]}

ê°œì„  ìš”êµ¬ì‚¬í•­:
- í”¼ë“œë°±ì˜ ê°œì„ ì ì„ ëª¨ë‘ ë°˜ì˜í•  ê²ƒ
- ê¸°ì¡´ ì¢‹ì€ ë¶€ë¶„ì€ ìœ ì§€í•  ê²ƒ
- SEO í‚¤ì›Œë“œë¥¼ ë” ìì—°ìŠ¤ëŸ½ê²Œ ë…¹ì—¬ë‚¼ ê²ƒ
- ë§ˆí¬ë‹¤ìš´ í˜•ì‹ ìœ ì§€
- ì „ì²´ ì´ˆì•ˆì„ ì™„ì„±ëœ í˜•íƒœë¡œ ì‘ì„±"""

    response = llm_writer.invoke([HumanMessage(content=prompt)])

    return {
        "draft":          response.content.strip(),
        "revision_count": revision_count + 1,
        "logs":           [f"ğŸ”„ [Revise] {revision_count + 1}ì°¨ ìˆ˜ì • ì™„ë£Œ"],
    }


# â”€â”€ Node 8: Publish â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def publish(state: BlogState) -> dict:
    """
    [Node 8] Velog ë°œí–‰ (ë˜ëŠ” íŒŒì¼ ì €ì¥)
    
    AUTO_PUBLISH=true  â†’ Velog GraphQL APIë¡œ ì‹¤ì œ ë°œí–‰
    AUTO_PUBLISH=false â†’ drafts/ í´ë”ì— ë§ˆí¬ë‹¤ìš´ íŒŒì¼ë¡œ ì €ì¥
    """
    draft = state.get("draft") or ""
    seo_title = state.get("seo_title") or state.get("topic") or "ë¸”ë¡œê·¸ ì´ˆì•ˆ"
    tags = state.get("velog_tags") or []
    meta_desc = state.get("meta_description") or ""

    # ì°¸ê³  ë¬¸í—Œ ì„¹ì…˜ ì¶”ê°€
    references = state.get("references") or []
    if references:
        ref_section = "\n\n---\n\n## ì°¸ê³ \n" + "\n".join(f"- {url}" for url in references[:5])
        final_content = draft + ref_section
    else:
        final_content = draft

    # ë©”íƒ€ ì •ë³´ í‘¸í„°
    footer = (
        f"\n\n---\n"
        f"*ì´ ê¸€ì€ LangGraph + Geminië¡œ ìë™ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.*  \n"
        f"*í’ˆì§ˆ ì ìˆ˜: {state.get('quality_score', 0)}/10 | "
        f"ìˆ˜ì • íšŸìˆ˜: {state.get('revision_count', 0)}íšŒ*"
    )
    final_content += footer

    try:
        if settings.auto_publish:
            result = publish_to_velog(
                title=seo_title,
                body=final_content,
                tags=tags,
                meta_description=meta_desc,
                is_temp=False,
            )
            log_msg = f"ğŸš€ [Publish] Velog ë°œí–‰ ì™„ë£Œ: {result['url']}"
        else:
            result = save_draft_to_file(
                title=seo_title,
                body=final_content,
                tags=tags,
                meta_description=meta_desc,
            )
            log_msg = f"ğŸ’¾ [Publish] ì´ˆì•ˆ ì €ì¥: {result['filename']}"

    except Exception as e:
        result = {"success": False, "url": None}
        log_msg = f"âŒ [Publish] ë°œí–‰ ì‹¤íŒ¨: {e}"

    return {
        "final_draft":  final_content,
        "velog_url":    result.get("url"),
        "is_published": result.get("success", False) and settings.auto_publish,
        "logs":         [log_msg],
    }
